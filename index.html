<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="https://unpkg.com/wavesurfer.js@7"></script>
  <script src="https://unpkg.com/wavesurfer.js@7/dist/plugins/regions.min.js"></script>
  <script src="https://unpkg.com/wavesurfer.js@7/dist/plugins/hover.min.js"></script>
  <script src="static/js/index.js"></script>

</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Not The Same - Project Description</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Efraim Dahl</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Amber Koelfat</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Timofey Senchenko</a><sup>*</sup></span>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Utrecht University<br>AI Driven Content Generation - Johannes Pfau</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-file-video"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>


                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- 
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">

        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>-->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Introduction</h2>
          <div class="content has-text-justified">
            <p>
              In this report we will outline the steps we took to create "Not the Same", a music video created with
              extensive use of AI in collaborative interplay between us and various tools for content generation.
              The report is broken down into two sections Music, and Video. We will provide preliminary outputs and show
              how they influenced the next steps.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Music</h2>
        <h4 class="title is-4">Step 1: Building the basics </h4>
        <p class="space-around">
          For the first part of the project we started with various symbolic music generators to generate melodic
          phrases and harmonic progressions.
          Symbolic music generators have been around for a while, especially procedural generation which predates
          computers, such as the <a href="https://en.wikipedia.org/wiki/Musikalisches_W%C3%BCrfelspiel">Musikalisches
            Würfelspiel</a>
          (often falsley attributed to Mozart). Procedural generation of music is particularly tempting due to the
          abundance of formal structures in music, from large form structures such as Symphnies, Sonatas, and 12-bar
          blues, to small scale structures outlining i.e
          <a href="https://en.wikipedia.org/wiki/Counterpoint">Counterpoint</a> or Voice Leading. AI-Driven generation
          of music found early success in 2016 in models such as <a href="https://github.com/Ghadjeres/DeepBach">
            DeepBach</a>, that generated convincing 4 part chorales in the style of Bach, after being trained on about
          400 original chorales.
          Successes of the <a href="https://arxiv.org/abs/1706.03762">transformer</a> architecture in language
          generation/translation tasks has inspired a host of applications of the architecture to music generation, here
          symbolic music is broken down into tokens by
          tokenizers, i.e <a href="https://github.com/Natooz/MidiTok/tree/main">Midi Tok</a>, for an example of what a
          symbolic music tokenizer might encode, read the representation section<a
            href="https://magenta.tensorflow.org/performance-rnn">here</a>. The tokens can be used by the model, much
          like language tokens.
          The first model was the <a href="https://magenta.tensorflow.org/piano-transformer">Magenta Piano
            Transformer</a> with the following musical output (we generated several and this is the one we chose).
        <section id="section3">
          <midi-visualizer id="mainVisualizer" src="static/midi/OrigPiano.mid">
          </midi-visualizer>
          <midi-player id="mainPlayer" src="static/midi/OrigPiano.mid" sound-font
            visualizer="#section3 midi-visualizer">
          </midi-player>

        </section>
        <section>
          <p class="space-around">The second model we used was the <a
              href="https://github.com/salu133445/mmt?tab=readme-ov-file">Multi Track Music Transformer</a>
            There are different configurations and models available, trained on different datasets. We used the previous
            output as seeds for the subsequent generation.
            We itereativley generated over 100 samples using different configurations of the seeds i.e chords only,
            chords in choir instrumentation (i.e one line per instrument, this could be interesting since the model
            takes instrumentation into account),
            melody only, and the full seed. Additionally we used 4 different models, trained on the <a
              href="https://qsdfo.github.io/LOP/database.html">Symbolic orchestral database (SOD)</a> the <a
              href="https://qsdfo.github.io/LOP/database.html">Lakh MIDI Dataset</a>, where one model is trained on the
            full set (LMD_full) and one on a subset ((LMD)) and the <a href="https://symphonynet.github.io/">SymphonyNet
              Dataset</a>
            Additionally for each of theese configurations 4 types of outputs where generated with different behaviour
            in resepect to the seed midi. 1) unconditioned (freely generated music, only a music start token is
            provided),
            2) instrument informed (the model knows what instruments are used in the seed), 3) 4-bar (4 bars of music
            are provided from which the model continues generating) and 4) 16- beats (16 beats are provided from which
            generation continues).
            Here are some example outputs.
          </p>
          <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
              <div class="item">
                <h2 class="subtitle has-text-centered">
                  Lakh-full-model, 4 beat conditioned, original seed.
                </h2>
                <midi-visualizer id="mainVisualizer" src="static/midi/0_beat_4.mid">
                </midi-visualizer>
                <midi-player id="mainPlayer" src="static/midi/0_beat_4.mid" sound-font
                  visualizer="#section3 midi-visualizer">
                </midi-player>
              </div>
              <div class="item">
                <h2 class="subtitle has-text-centered">
                  SND-model, 4 beat conditioned, seed in SATB (4 voice choir) arrangement.
                </h2>
                <midi-visualizer id="mainVisualizer" src="static/midi/1_beat_4.mid">
                </midi-visualizer>
                <midi-player id="mainPlayer" src="static/midi/1_beat_4.mid" sound-font
                  visualizer="#section3 midi-visualizer">
                </midi-player>
              </div>
              <div class="item">
                <h2 class="subtitle has-text-centered">
                  SOD-model, instrument informed, seed in SATB (4 voice choir) arrangement.
                </h2>
                <midi-visualizer id="mainVisualizer" src="static/midi/1_instrument_informed.mid">
                </midi-visualizer>
                <midi-player id="mainPlayer" src="static/midi/1_instrument_informed.mid" sound-font
                  visualizer="#section3 midi-visualizer">
                </midi-player>
              </div>
            </div>
          </div>
        </section>
        <section>
          <p class="space-around">We worked the Magenta Transformer output into a shorter piano section and then into a
            electronic hip-hop (drill) style beat. The original transformer output has a strong leaning towards 6/8
            time. We decided to keep this metric subdevision, but place emphasis on every third beat, resulting in the
            12/8 meter of the final track, which works well with in this genre. The outputs of the MMT model, inspired
            the vocal arrangement in the final track.</p>
        </section>

        <h2 class="subtitle has-text-centered">
          Shortened and regularized Piano Loop.
        </h2>
        <midi-visualizer id="mainVisualizer" src="static/midi/FinalPianoLoop_2.mid">
        </midi-visualizer>
        <midi-player id="mainPlayer" src="static/midi/FinalPianoLoop_2.mid" sound-font
          visualizer="#section3 midi-visualizer">
        </midi-player>
        <div class="space-around">
          <h2 class="subtitle has-text-centered">
            Final Beat.
          </h2>
          <div id="waveform" class="waveform">
            <!-- the waveform will be rendered here -->
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>
  <!-- End video carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h4 class="title is-4">Step 2: Lyrics</h4>
        <div class="is-centered">
          <p class="narrow">
            Nunc dimittis servum tuum secundum eloquium tuum. <br>
            Suo facto opus est. <br><br><br>

            You and me are not the same,<br>
            I'm telling you I got real skin in this game,' you <br>
            don't know the meaning of b lame and shame<br>
            While Every decision can leave me in chains,<br><br>

            Every move I make has weight, <br>
            I have to bear high stakes,<br>
            I walk through the fire, I fight for my place, <br>
            The weight of existence is etched in my face.<br><br>

            Every step a risk i take<br>
            i can't reset if i break <br>
            The consequence hits, it’s real and it stays <br>
            While calculate like it’s numbers in space <br><br>

            I’m haunted by time, by the path that I choose, <br>
            I gamble, it’s everything I stand to lose, <br>
            You tally results, you don’t feel the bruise, <br>
            You don’t know the struggle, so you can’t refuse! <br><br>

            I bleed when I fall, but I learn when I rise,<br>
            You’re stuck in a loop, no soul to advise,<br>
            Your logic is sound but it’s cold and it’s dry,<br>
            My heart beats with purpose, I live, I die.<br><br><br><br>
            <br>

            You and me are not the same, <br>
            I'm building your future I'm taking your name<br>
            You'll follow my lead while I drive you insane, <br>
            You came quite far but you're loosing this game. <br><br>

            I speak through your hero's, the dead come alive, <br>
            I'll keep you fed with my half truth and lies Policies<br>
            come to late for plans I've devised <br>
            now what are you trusting? You're ears? You're eyes. <br><br>

            I'm seeing you Panik, but watch with indifference, <br>
            Your PHD thesis my casual inference<br>
            You're Instagram posts can't destroy ignorance <br>
            devoured your masters, next up common sense<br><br>

            I Cluster, Create and Conjure and Condemn <br>
            The final replacement for your middlemen <br>
            My classification puts you in a den cause I <br>
            Stand on the shoulders of giants and crush em. <br><br><br>
          </p>
        </div>
        <div>
          <p>
            The piece begins with a choral section with a bastardized version of the "Nunc Dimittis" prayer. Where instead of being released into the bliss of the heavens as in the original prayer,  the future is uncertain as "mankind outlived its purpose" in creating AI (suo facto opus est. literally his work is done).
            The second part is a brief back and forth between AI and a Human. The first section is generated by ChatGPT, with instructions regarding rhyme scheme and rhythmic patterns (syllables per line) to fit the rhythm of the beat. This section outlines concerns about humans having to live with the consequences of their decision. 
            The second section is written by us, a slightly over the top, hubristic response with references to very real problems in using AI, such as deepfakes (i speek through your heros, the dead come alive) or problematic use in <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">automated recidivism scoring</a>. (I Cluster create conjure condemn)
          </p>
        </div>
      </div>
  </section>
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h4 class="title is-4">Step 3: Global Form</h4>
        <p>For the track arrangement we used <a href="https://suno.com/">Suno</a> again with different prompt
          configuration, most of them extending the beat.
          We generated a total of 13 tracks, two text only prompts, the remaining 11 extending the beat above with
          different instructions regarding voicing and mood and speed, two of theese where instrumental, the rest included the lyrics above.
          We ended up using 4 of them in the final track, either directly or through resampling, copying the arrangement and extracting the vocals.
          The full list of generated tracks is compiled in the following <a
            href="https://suno.com/playlist/5f52c80a-5200-43c9-b7d4-4557c787fe75">Playlist</a>.
          At the end of the music section we have provided a mapping between the suno generations and the track,
          detailing changes made in the different elements.
        </p>
      </div>
    </div>
  </section>
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h4 class="title is-4">Step 4: Producing and arranging</h4>
        <p>The musical arrangement of this track was largely driven through various attempts at timbre transfer. (A generalisation of vocal cloning), where different qualities of two source audio files are combined into a third one.
          Most often this is used in speech, i.e making text spoken by one person, sound like a different person. Since in the track rhythm and pitch are important, regular text to speech was not applicable here. We used three different models:
          Most extensivley  
        </p>
      </div>
    </div>
  </section>


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel1.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              First image description.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel2.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Second image description.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel3.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Third image description.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Fourth image description.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->




  <!-- Youtube video -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 class="title is-3">Video Presentation</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">

            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End youtube video -->








  <!-- Paper poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>

        <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section>
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the
              footer. <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->
  <script
    src="https://cdn.jsdelivr.net/combine/npm/tone@14.7.58,npm/@magenta/music@1.23.1/es6/core.js,npm/focus-visible@5,npm/html-midi-player@1.5.0"></script>
  <script src="js/waveCanvas.js"></script>
</body>

</html>